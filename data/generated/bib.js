const generatedBibEntries = {
    "1d-minmax-shad": {
        "abstract": "Light scattering in a participating medium is responsible for several important effects we see in the natural world. In the presence of occluders, computing single scattering requires integrating the illumination scattered towards the eye along the camera ray, modulated by the visibility towards the light at each point. Unfortunately, incorporating volumetric shadows into this integral, while maintaining real-time performance, remains challenging.In this paper we present a new real-time algorithm for computing volumetric shadows in single-scattering media on the GPU. This computation requires evaluating the scattering integral over the intersections of camera rays with the shadow map, expressed as a 2D height field. We observe that by applying epipolar rectification to the shadow map, each camera ray only travels through a single row of the shadow map (an epipolar slice), which allows us to find the visible segments by considering only 1D height fields. At the core of our algorithm is the use of an acceleration structure (a 1D minmax mipmap) which allows us to quickly find the lit segments for all pixels in an epipolar slice in parallel. The simplicity of this data structure and its traversal allows for efficient implementation using only pixel shaders on the GPU.",
        "address": "New York, NY, USA",
        "author": "Chen, Jiawen and Baran, Ilya and Durand, Fr\\'{e}do and Jarosz, Wojciech",
        "booktitle": "Symposium on Interactive 3D Graphics and Games",
        "doi": "10.1145/1944745.1944752",
        "isbn": "9781450305655",
        "keywords": "field: global illumination, performance: real-time, approach: shadow mapping, calculation space: screen space, main technique: epipolar rays, evaluation: quantitative, calculation: pre-calculated volumetric scattering, global illumination",
        "location": "San Francisco, California",
        "pages": "39\u201346",
        "publisher": "Association for Computing Machinery",
        "series": "I3D '11",
        "title": "{R}eal-time {V}olumetric {S}hadows {U}sing 1D {M}in-max {M}ipmaps",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/1944745.1944752",
        "year": "2011"
    },
    "baked-gi": {
        "abstract": "Global Illumination is affected by the slightest change in a 3D scene, requiring a complete reevaluation of the distributed light. In cases where real-time algorithms are not applicable due to high demands on the achievable accuracy, this recomputation from scratch results in artifacts like flickering or noise, disturbing the visual appearance and negatively affecting interactive lighting design workflows.We propose a novel system tackling this problem by providing incremental updates of a baked global illumination solution after scene modifications, and a re-convergence after a few seconds. Using specifically targeted incremental data structures and prioritization strategies in a many-light global illumination algorithm, we compute a differential update from one illumination state to another. We further demonstrate the use of a novel error balancing strategy making it possible to prioritize the illumination updates.",
        "address": "New York, NY, USA",
        "articleno": "4",
        "author": "Luksch, Christan and Wimmer, Michael and Schw\\\"{a}rzler, Michael",
        "booktitle": "Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",
        "doi": "10.1145/3306131.3317015",
        "isbn": "9781450363105",
        "keywords": "other: instant radiosity, field: global illumination, performance: interactive, approach: path tracing, calculation space: world space, main technique: incremental baking, evaluation: quantitative, calculation: data-driven",
        "location": "Montreal, Quebec, Canada",
        "numpages": "10",
        "pages": "1-10",
        "publisher": "Association for Computing Machinery",
        "series": "I3D '19",
        "title": "Incrementally baked global illumination",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/3306131.3317015",
        "year": "2019"
    },
    "cone-tracing": {
        "abstract": "Abstract Indirect illumination is an important element for realistic image synthesis, but its computation is expensive and highly dependent on the complexity of the scene and of the BRDF of the involved surfaces. While off-line computation and pre-baking can be acceptable for some cases, many applications (games, simulators, etc.) require real-time or interactive approaches to evaluate indirect illumination. We present a novel algorithm to compute indirect lighting in real-time that avoids costly precomputation steps and is not restricted to low-frequency illumination. It is based on a hierarchical voxel octree representation generated and updated on the fly from a regular scene mesh coupled with an approximate voxel cone tracing that allows for a fast estimation of the visibility and incoming energy. Our approach can manage two light bounces for both Lambertian and glossy materials at interactive framerates (25\u201370FPS). It exhibits an almost scene-independent performance and can handle complex scenes with dynamic content thanks to an interactive octree-voxelization scheme. In addition, we demonstrate that our voxel cone tracing can be used to efficiently estimate Ambient Occlusion.",
        "author": "Crassin, Cyril and Neyret, Fabrice and Sainz, Miguel and Green, Simon and Eisemann, Elmar",
        "doi": "https://doi.org/10.1111/j.1467-8659.2011.02063.x",
        "eprint": " https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.02063.x ,",
        "journal": "Computer Graphics Forum",
        "keywords": "evaluation: comparative, approach: path tracing, calculation space: world space, field: global illumination, main technique: cone-tracing , performance: real-time, calculation: data-driven",
        "number": "7",
        "pages": "1921-1930",
        "series": "Computer Graphics Forum",
        "title": "Interactive Indirect Illumination Using Voxel Cone Tracing",
        "type": "article",
        "url": " https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.02063.x ,",
        "volume": "30",
        "year": "2011"
    },
    "light-field-tracing-gi": {
        "abstract": "We introduce a new data structure and algorithms that employ it to compute real-time global illumination from static environments. Light field probes encode a scene's full light field and internal visibility. They extend current radiance and irradiance probe structures with per-texel visibility information similar to a G-buffer and variance shadow map. We apply ideas from screen-space and voxel cone tracing techniques to this data structure to efficiently sample radiance on world space rays, with correct visibility information, directly within pixel and compute shaders. From these primitives, we then design two GPU algorithms to efficiently gather real-time, viewer-dependent global illumination onto both static and dynamic objects. These algorithms make different tradeoffs between performance and accuracy. Supplemental GLSL source code is included.",
        "address": "New York, NY, USA",
        "articleno": "2",
        "author": "McGuire, Morgan and Mara, Mike and Nowrouzezahrai, Derek and Luebke, David",
        "booktitle": "Proceedings of the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",
        "doi": "10.1145/3023368.3023378",
        "isbn": "9781450348867",
        "keywords": "field: global illumination, performance: real-time, approach: path tracng, calculation space: world space, main technique: light field probes, calculation: pre-calculated, evaluation: quantitative",
        "location": "San Francisco, California",
        "numpages": "11",
        "pages": "1-11",
        "publisher": "Association for Computing Machinery",
        "series": "I3D '17",
        "title": "Real-time global illumination using precomputed light field probes",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/3023368.3023378",
        "year": "2017"
    },
    "lpv-indirect-illum": {
        "abstract": "This paper introduces a new scalable technique for approximating indirect illumination in fully dynamic scenes for real-time applications, such as video games. We use lattices and spherical harmonics to represent the spatial and angular distribution of light in the scene. Our technique does not require any precomputation and handles large scenes with nested lattices. It is primarily targeted at rendering single-bounce indirect illumination with occlusion, but can be extended to handle multiple bounces and participating media. We demonstrate that our method produces plausible results even when running on current game console hardware with a budget of only a few milliseconds for performing all computation steps for indirect lighting. We evaluate our technique and show it in combination with a variety of popular real-time rendering techniques.",
        "address": "New York, NY, USA",
        "author": "Kaplanyan, Anton and Dachsbacher, Carsten",
        "booktitle": "Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games",
        "doi": "10.1145/1730804.1730821",
        "isbn": "9781605589398",
        "keywords": "field: global illumination, evaluation: quantitative, performance: real-time, approach: texture mapping, calculation space: screen space, main technique: light propagation volumes, other: spherical harmonics, calculation: data-driven",
        "location": "Washington, D.C.",
        "numpages": "9",
        "pages": "99\u2013107",
        "publisher": "Association for Computing Machinery",
        "series": "I3D '10",
        "title": "{Cascaded} light propagation volumes for real-time indirect illumination",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/1730804.1730821",
        "year": "2010"
    },
    "photon-map-nn": {
        "abstract": "Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks\u2014a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achieve interactive framerates even on large datasets. We conduct in-depth evaluations of the method's performance, including visual quality, stochastic noise, inference and rendering speeds, and accuracy regarding illumination and phase function awareness. Results are compared to ray marching, path tracing and photon mapping. Our findings show that Photon Field Networks can faithfully represent indirect global illumination within the boundaries of the trained phase spectrum while exhibiting less stochastic noise and rendering at a significantly faster rate than traditional methods.",
        "author": "Bauer, David and Wu, Qi and Ma, Kwan-Liu",
        "doi": "10.1109/TVCG.2023.3327107",
        "issn": "1941-0506",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "keywords": "other: neural network, field: global illumination, performance: real-time, approach: photon mapping, calculation space: world space, main technique: photon field networks, evaluation: comparative, calculation: pre-calculated",
        "month": "Jan",
        "number": "1",
        "pages": "975-985",
        "series": "IEEE Transactions on Visualization and Computer Graphics",
        "title": "Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination",
        "type": "article",
        "volume": "30",
        "year": "2024"
    },
    "photon-mapping": {
        "abstract": "\"Indirect lighting, also known as global illumination, is a crucial effect in photorealistic images. While there are a number of effective global illumination techniques based on precomputation that work well with static scenes, including global illumination for scenes with dynamic lighting and dynamic geometry remains a challenging problem. In this chapter, we describe a real-time global illumination algorithm based on photon mapping that evaluates several bounces of indirect lighting without any precomputed data in scenes with both dynamic lighting and fully dynamic geometry. We explain both the pre- and post-processing steps required to achieve dynamic high-quality illumination within the limits of a realtime frame budget.\",",
        "address": "\"Berkeley, CA\",",
        "author": "Smal, Niklas and Aizenshtein, Maksim",
        "booktitle": "\"Ray Tracing Gems: High-Quality and Real-Time Rendering with DXR and Other APIs\",",
        "doi": "\"10.1007/978-1-4842-4427-2_24\",",
        "editor": "\"Haines, Eric and Akenine-M{\\\"o}ller, Tomas\",",
        "isbn": "\"978-1-4842-4427-2\",",
        "keywords": "field: global illumination, performance: real-time, approach: photon mapping, calculation space: world space, main technique: photon mapping, evaluation: quantitative, calculation: pre-calculated",
        "pages": "\"409--436\",",
        "publisher": "\"Apress\",",
        "series": "Apress",
        "title": "{Real}-Time Global Illumination with Photon Mapping",
        "type": "inbook",
        "url": "\"https://doi.org/10.1007/978-1-4842-4427-2_24\",",
        "year": "2019"
    },
    "restir-gi": {
        "abstract": "Abstract Even with the advent of hardware-accelerated ray tracing in modern GPUs, only a small number of rays can be traced at each pixel in real-time applications. This presents a significant challenge for path tracing, even when augmented with state-of-the art denoising algorithms. While the recently-developed ReSTIR algorithm [BWP\u221720] enables high-quality renderings of scenes with millions of light sources using just a few shadow rays at each pixel, there remains a need for effective algorithms to sample indirect illumination. We introduce an effective path sampling algorithm for indirect lighting that is suitable to highly parallel GPU architectures. Building on the screen-space spatio-temporal resampling principles of ReSTIR, our approach resamples multi-bounce indirect lighting paths obtained by path tracing. Doing so allows sharing information about important paths that contribute to lighting both across time and pixels in the image. The resulting algorithm achieves a substantial error reduction compared to path tracing: at a single sample per pixel every frame, our algorithm achieves MSE improvements ranging from 9.3\u00d7 to 166\u00d7 in our test scenes. In conjunction with a denoiser, it leads to high-quality path traced global illumination at real-time frame rates on modern GPUs.",
        "author": "Ouyang, {Y} and Liu, {S} and Kettunen, {M} and Pharr, {M} and Pantaleoni, {J}",
        "doi": "https://doi.org/10.1111/cgf.14378",
        "eprint": "https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14378",
        "journal": "Computer Graphics Forum",
        "keywords": "field: global illumination, performance: real-time, approach: path tracing, calculation space: screen space, main technique: de-noising, evaluation: quantitative, calculation: data-driven, other: importance sampling",
        "number": "8",
        "pages": "17-29",
        "series": "Computer Graphics Forum",
        "title": "{ReSTIR} GI: Path Resampling for Real-Time Path Tracing",
        "type": "article",
        "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14378",
        "volume": "40",
        "year": "2021"
    },
    "simplest-single-scat": {
        "abstract": "We consider real-time rendering of scenes in participating media , capturing the effects of light scattering in fog, mist and haze. While a number of sophisticated approaches based on Monte Carlo and finite element simulation have been developed, those methods do not work at interactive rates. The most common real-time methods are essentially simple variants of the OpenGL fog model. While easy to use and specify, that model excludes many important qualitative effects like glows around light sources, the impact of volumetric scattering on the appearance of surfaces such as the diffusing of glossy highlights, and the appearance under complex lighting such as environment maps. In this paper, we present an alternative physically based approach that captures these effects while maintaining real time performance and the ease-of-use of the OpenGL fog model. Our method is based on an explicit analytic integration of the single scattering light transport equations for an isotropic point light source in a homogeneous participating medium. We can implement the model in modern programmable graphics hardware using a few small numerical lookup tables stored as texture maps. Our model can also be easily adapted to generate the appearances of materials with arbitrary BRDFs, environment map lighting, and precomputed radiance transfer methods, in the presence of participating media. Hence, our techniques can be widely used in real-time rendering.",
        "address": "New York, NY, USA",
        "author": "Sun, Bo and Ramamoorthi, Ravi and Narasimhan, Srinivasa G. and Nayar, Shree K.",
        "doi": "10.1145/1073204.1073309",
        "issn": "0730-0301",
        "issue_date": "July 2005",
        "journal": "ACM Trans. Graph.",
        "keywords": "field: global illumination, evaluation: comparative, performance: real-time, approach: other, calculation space: world space, main technique: integral precalculation, calculation: pre-calculated",
        "month": "Jul",
        "number": "3",
        "numpages": "10",
        "pages": "1040\u20131049",
        "publisher": "Association for Computing Machinery",
        "series": "ACM Trans. Graph.",
        "title": "{A} practical analytic single scattering model for real time rendering",
        "type": "article",
        "url": "https://doi.org/10.1145/1073204.1073309",
        "volume": "24",
        "year": "2005"
    },
    "spat-temp-gi": {
        "abstract": "We introduce a reconstruction algorithm that generates a temporally stable sequence of images from one path-per-pixel global illumination. To handle such noisy input, we use temporal accumulation to increase the effective sample count and spatiotemporal luminance variance estimates to drive a hierarchical, image-space wavelet filter [Dammertz et al. 2010]. This hierarchy allows us to distinguish between noise and detail at multiple scales using local luminance variance.Physically based light transport is a long-standing goal for realtime computer graphics. While modern games use limited forms of ray tracing, physically based Monte Carlo global illumination does not meet their 30 Hz minimal performance requirement. Looking ahead to fully dynamic real-time path tracing, we expect this to only be feasible using a small number of paths per pixel. As such , image reconstruction using low sample counts is key to bringing path tracing to real-time. When compared to prior interactive reconstruction filters, our work gives approximately 10\\texttimes {} more temporally stable results, matches reference images 5--47 \\% better (according to SSIM), and runs in just 10 ms (\u00b1 15\\%) on modern graphics hardware at 1920\\texttimes{}1080 resolution.",
        "address": "New York, NY, USA",
        "articleno": "2",
        "author": "Schied, Christoph and Kaplanyan, Anton and Wyman, Chris and Patney , Anjul and Chaitanya, Chakravarty R. Alla and Burgess, John and Liu, Shiqiu and Dachsbacher, Carsten and Lefohn, Aaron and Salvi, Marco",
        "booktitle": "Proceedings of High Performance Graphics",
        "doi": "10.1145/3105762.3105770",
        "isbn": "9781450351010",
        "keywords": "other: reconstruction, field: global illumination, performance: real-time, approach: path tracing, calculation space: screen space, main technique: de-noising, evaluation: comparative, calculation: data-driven",
        "location": "Los Angeles, California",
        "numpages": "12",
        "pages": "1-12",
        "publisher": "Association for Computing Machinery",
        "series": "HPG '17",
        "title": "Spatiotemporal variance-guided filtering: real-time reconstruction for path-traced global illumination",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/3105762.3105770",
        "year": "2017"
    }
};